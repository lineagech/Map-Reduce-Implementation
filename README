Name: Chia-Hao, Chang
Email: cuc1057@psu.edu
Name: Cho-Chun, Chiu
Email: cuc496@psu.edu

Concurrency Mechanisms:
Since a reducer and a mapper share a buffer and count, so we use
pthread_mutex_lock to protect them from being overwritten. In order to make
sure some statements can be executed synchronously, we use Conditional wait and
signal mechanism. By pthread_cond_wait and pthread_cond_signal, one thread can
wait until receiving signal from the other.

Producer-Consumer Problem:
When a mapper (producesr) sees buffer is full, it goes to sleep until
it receives the signal from the reducer. The reducer will send a signal to
inform the waiting mapper to wake it up, when it take out data from the buffer.
On the other hand, when the reducer finds out that the buffer is empty, it also
goes to sleep until getting informed by mapper. Mappers will also wake the
reducer up when they insert data into buffer.

Known Bugs:
We solved them. Thank you for the help from Piazza and office hour.

Statistics (Use microseconds):
@Test: 0, perf-eval.txt, 1, 100, 12310000
@Test: 1, perf-eval.txt, 2, 100, 10380000
@Test: 2, perf-eval.txt, 4, 100, 11270000
@Test: 3, perf-eval.txt, 8, 100, 27260000
@Test: 4, perf-eval.txt, 16, 100, 31200000
@Test: 5, perf-eval.txt, 32, 100, 25660000
@Test: 6, perf-eval.txt, 64, 100, 26260000
@Test: 7, perf-eval.txt, 1, 1000, 12160000
@Test: 8, perf-eval.txt, 2, 1000, 11730000
@Test: 9, perf-eval.txt, 4, 1000, 10850000
@Test: 10, perf-eval.txt, 8, 1000, 13020000
@Test: 11, perf-eval.txt, 16, 1000, 21020000
@Test: 12, perf-eval.txt, 32, 1000, 25240000
@Test: 13, perf-eval.txt, 64, 1000, 24860000
@Test: 14, perf-eval.txt, 1, 10000, 12410000
@Test: 15, perf-eval.txt, 2, 10000, 10080000
@Test: 16, perf-eval.txt, 4, 10000, 10600000
@Test: 17, perf-eval.txt, 8, 10000, 14360000
@Test: 18, perf-eval.txt, 16, 10000, 21230000
@Test: 19, perf-eval.txt, 32, 10000, 23330000
@Test: 20, perf-eval.txt, 64, 10000, 24130000

Performance Evaluation:
Intuitively, we expect that the completion time will be shorter, when either
the size of buffer or the number of threads increases. Since we have two
variables(buffer size and number of thread), we analyze completion time by
fixing one of them each time.

Given a fixed buffer size, we found out that the completion time increases,
when we execute the program by using more threads, which is counterintuitive.
We infer two possible reasons for this result. One possible reason is that the
overhead of switching between different threads is too heavy to reduce the
completion time. Context switch is explicit overhead, and there also might be
implicit overhead, such as creating thread, etc. Those overheads increase and
delay the completion time. The other possible reason is that reducer could
possibly encounter more busy waiting times in our concurrency mechanism. Since
reducer processes data sequentially, it might wait at the certain buffer until
the corresponding mapper inserts data to that buffer. Mapper could be late to
produce data, if its running time wasn't allocated equally. The more threads
the program is executed, the more chance getting into this scenario.

Given a fixed number of threads, when size of buffer becomes larger, the
completion time of 8 and 16 threads get shorten, which meets our expectation.
However, there is no much difference by increasing the size of buffer, when
the program is executed by more threads (32 and 64 threads). We infer that
since the program is executed on the 8-core CPU, 8 threads is optimal. If the
number of threads is much greater than 8 (32 or 64), the single CPU has to
process multiple threads, which degrades the efficiency. In that case, since
each mapper can not be running efficiently, the buffer won't be full. That is
the reason that larger buffer does not provide any improvement in 32/64 threads.

Sources Consulted:
